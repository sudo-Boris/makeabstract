{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borismeinardus/Library/Caches/pypoetry/virtualenvs/makeabstract-y-b1AI76-py3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "data_path = Path('../arxiv-metadata-oai-snapshot.json')\n",
    "def get_metadata():\n",
    "    with open(data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC energies\n",
      "\n",
      "Abstract:   A fully differential calculation in perturbative quantum chromodynamics is\n",
      "presented for the production of massive photon pairs at hadron colliders. All\n",
      "next-to-leading order perturbative contributions from quark-antiquark,\n",
      "gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n",
      "all-orders resummation of initial-state gluon radiation valid at\n",
      "next-to-next-to-leading logarithmic accuracy. The region of phase space is\n",
      "specified in which the calculation is most reliable. Good agreement is\n",
      "demonstrated with data from the Fermilab Tevatron, and predictions are made for\n",
      "more detailed tests with CDF and DO data. Predictions are shown for\n",
      "distributions of diphoton pairs produced at the energy of the Large Hadron\n",
      "Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\n",
      "boson are contrasted with those produced from QCD processes at the LHC, showing\n",
      "that enhanced sensitivity to the signal can be obtained with judicious\n",
      "selection of events.\n",
      "\n",
      "Ref: Phys.Rev.D76:013009,2007\n"
     ]
    }
   ],
   "source": [
    "metadata = get_metadata()\n",
    "for paper in metadata:\n",
    "    paper_dict = json.loads(paper)\n",
    "    print('Title: {}\\n\\nAbstract: {}\\nRef: {}'.format(paper_dict.get('title'), paper_dict.get('abstract'), paper_dict.get('journal-ref')))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 3210.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the titles and abstracts\n",
    "\n",
    "TITLES = []\n",
    "ABSTRACTS = []\n",
    "metadata = get_metadata()\n",
    "for i, paper in enumerate(metadata):\n",
    "    paper_dict = json.loads(paper)\n",
    "    TITLES.append(paper_dict.get('title'))\n",
    "    # Remove the first empty space\n",
    "    ABSTRACTS.append(paper_dict.get('abstract')[1:])\n",
    "\n",
    "    if i == 9:\n",
    "        break\n",
    "\n",
    "len(TITLES), len(ABSTRACTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "words_old = sorted(list(set(''.join(ABSTRACTS).split())))\n",
    "words = [\".\", \",\", \"!\", \"?\"]\n",
    "for word in words_old:\n",
    "    if word.endswith(('.', ',', '!', '?')):\n",
    "        words.append(word[:-1])\n",
    "    else:\n",
    "        words.append(word)\n",
    "words = sorted(list(set(words)))\n",
    "stoi = {s:i+1 for i,s in enumerate(words)}\n",
    "stoi['<S>'] = 0\n",
    "words.append('<S>')\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(text: str):\n",
    "    split_text = list(''.join(text).split())\n",
    "    words = []\n",
    "    for word in split_text:\n",
    "        # Split up word and punctuation\n",
    "        if word.endswith(('.', ',', '!', '?')):\n",
    "            words.append(word[:-1])\n",
    "            words.append(word[-1])\n",
    "        else:\n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(abstracts: list = ABSTRACTS, block_size: int = 3):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for abstract in abstracts:\n",
    "        context = [0] * block_size\n",
    "        decomposed_abstract = split(abstract)\n",
    "        decomposed_abstract.append('<S>')\n",
    "        for word in decomposed_abstract:\n",
    "            ix = stoi[word]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            # print(' '.join(itos[i] for i in context), '--->', itos[ix])\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([146, 3]) torch.Size([146])\n",
      "torch.Size([152, 3]) torch.Size([152])\n",
      "torch.Size([125, 3]) torch.Size([125])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(ABSTRACTS)\n",
    "block_size = 3\n",
    "n1 = int(0.8*len(ABSTRACTS))\n",
    "n2 = int(0.9*len(ABSTRACTS))\n",
    "\n",
    "Xtr, Ytr = build_dataset(ABSTRACTS[:n1], block_size)\n",
    "Xdev, Ydev = build_dataset(ABSTRACTS[n1:n2], block_size)\n",
    "Xte, Yte = build_dataset(ABSTRACTS[n2:], block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define generator for reproducability\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build embedding table for all words\n",
    "#   Size: (len(words), 2)\n",
    "C = torch.randn(len(), 2, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5674, -0.2373])\n",
      "torch.Size([146, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "emb = C[0] # embedding for <S>\n",
    "print(emb)\n",
    "emb = C[Xtr]\n",
    "print(emb.shape) # (n_bigrams, block_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build first layer of network\n",
    "W1 = torch.randn((6, 300), generator=g) # (embedding_size * block_size, 300)\n",
    "b1 = torch.randn((300,), generator=g) # (300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([146, 300])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (n_bigrams, block_size, 300)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build second layer of network\n",
    "W2 = torch.randn((300, len(words)), generator=g) # (300, all words)\n",
    "b2 = torch.randn((len(words),), generator=g) # (len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([146, 614])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get logits for each word in the vocabulary\n",
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([146, 614])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the probability of each word\n",
    "#   Get the 'count' of each word\n",
    "counts = logits.exp() # this maps all output values to be positive\n",
    "#   Get the probability of each word\n",
    "prob = counts / counts.sum(dim=1, keepdim=True)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.4471)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the loss (negative log likelihood)\n",
    "loss = -prob[torch.arange(Xtr.shape[0]), Ytr].log().mean()\n",
    "loss\n",
    "#   We will use the numerically stable cross entropy by pytorch to calculate the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring everything together nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all titles and abstracts\n",
    "TITLES_ = []\n",
    "ABSTRACTS_ = []\n",
    "metadata = get_metadata()\n",
    "for i, paper in enumerate(metadata):\n",
    "    paper_dict = json.loads(paper)\n",
    "    TITLES_.append(paper_dict.get('title'))\n",
    "    # Remove the first empty space\n",
    "    ABSTRACTS_.append(paper_dict.get('abstract')[1:])\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(ABSTRACTS_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts: 20\n",
      "Size of vocabulary: 1242\n",
      "torch.Size([2575, 20]) torch.Size([2575])\n",
      "torch.Size([193, 20]) torch.Size([193])\n",
      "torch.Size([390, 20]) torch.Size([390])\n"
     ]
    }
   ],
   "source": [
    "### Build dataset\n",
    "\n",
    "# Hyperparameters\n",
    "block_size = 20\n",
    "n_abstracts = 20\n",
    "\n",
    "ABSTRACTS = ABSTRACTS_[:n_abstracts]\n",
    "\n",
    "print(\"Number of abstracts: {}\".format(len(ABSTRACTS)))\n",
    "\n",
    "# Build the vocabulary of characters and mappings to/from integers\n",
    "words_old = sorted(list(set(''.join(ABSTRACTS).split())))\n",
    "words = [\".\", \",\", \"!\", \"?\"]\n",
    "for word in words_old:\n",
    "    if word.endswith(('.', ',', '!', '?')):\n",
    "        words.append(word[:-1])\n",
    "    else:\n",
    "        words.append(word)\n",
    "words = sorted(list(set(words)))\n",
    "stoi = {s:i+1 for i,s in enumerate(words)}\n",
    "stoi['<S>'] = 0\n",
    "words.append('<S>')\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(\"Size of vocabulary: {}\".format(len(words)))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(ABSTRACTS)\n",
    "# Xtr, Ytr = build_dataset(ABSTRACTS, block_size)\n",
    "\n",
    "# Split up data into train, dev, and test set\n",
    "n1 = int(0.8*len(ABSTRACTS))\n",
    "n2 = int(0.9*len(ABSTRACTS))\n",
    "\n",
    "Xtr, Ytr = build_dataset(ABSTRACTS[:n1], block_size)\n",
    "Xdev, Ydev = build_dataset(ABSTRACTS[n1:n2], block_size)\n",
    "Xte, Yte = build_dataset(ABSTRACTS[n2:], block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2575, 20]), torch.Size([2575]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Ytr.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 302262\n"
     ]
    }
   ],
   "source": [
    "### Define parameters of model\n",
    "#   Hyperparameters\n",
    "embedding_size = 10\n",
    "layer1_size = 200\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn(len(words), embedding_size, generator=g)\n",
    "W1 = torch.randn((embedding_size*block_size, layer1_size), generator=g)\n",
    "b1 = torch.randn((layer1_size,), generator=g)\n",
    "W2 = torch.randn((layer1_size, len(words)), generator=g)\n",
    "b2 = torch.randn((len(words),), generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(\"Number of parameters: {}\".format(sum(p.nelement() for p in parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch requires to set requires_grad to True for each parameter\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For logging\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.645042419433594\n",
      "8.900250434875488\n",
      "3.5007059574127197\n",
      "1.893397331237793\n",
      "0.4342920482158661\n",
      "0.15021176636219025\n",
      "0.056497007608413696\n",
      "0.03448440134525299\n",
      "0.14728078246116638\n",
      "0.014376739040017128\n",
      "0.01152978278696537\n",
      "0.014026682823896408\n",
      "0.010723850689828396\n",
      "0.011785866692662239\n",
      "0.010203469544649124\n",
      "0.01953755132853985\n",
      "0.015204143710434437\n",
      "0.08172937482595444\n",
      "0.012320811860263348\n",
      "0.11388636380434036\n",
      "0.014185449108481407\n"
     ]
    }
   ],
   "source": [
    "for i in range(20000): #200000\n",
    "  \n",
    "  # minibatch construct\n",
    "  mini_batch_size = 32\n",
    "  ix = torch.randint(0, Xtr.shape[0], (mini_batch_size,))\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xtr[ix]] # (32, 3, 2)\n",
    "  # layer 1\n",
    "  h = torch.tanh(emb.view(-1, emb.shape[1]*emb.shape[2]) @ W1 + b1) # (32, 300)\n",
    "  # layer 2\n",
    "  logits = h @ W2 + b2 # (32, 614)\n",
    "  #loss\n",
    "  loss = F.cross_entropy(logits, Ytr[ix])\n",
    "  if i % 1000 == 0:\n",
    "    print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 8_000 else 0.01\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  stepi.append(i)\n",
    "  lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb77b947640>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0297, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training performance\n",
    "# forward pass\n",
    "emb = C[Xtr] # (1119, 3, 2)\n",
    "# layer 1\n",
    "h = torch.tanh(emb.view(-1, emb.shape[1]*emb.shape[2]) @ W1 + b1) # (1119, 300)\n",
    "# layer 2\n",
    "logits = h @ W2 + b2 # (1119, 614)\n",
    "#loss\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38.5214, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluation performance\n",
    "# forward pass\n",
    "emb = C[Xdev] # (1119, 3, 2)\n",
    "# layer 1\n",
    "h = torch.tanh(emb.view(-1, emb.shape[1]*emb.shape[2]) @ W1 + b1) # (1119, 300)\n",
    "# layer 2\n",
    "logits = h @ W2 + b2 # (1119, 614)\n",
    "#loss\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize dimensions 0 and 1 of the embedding matrix C for all words\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Provide prompt to continue!\n",
    "#   Must be size of block_size\n",
    "prompt = \"NLP models use a large amounts of data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capabilities to categorize a clause based on the type of situation entity (e.g. , events , states and generic statements) the clause introduces to the discourse can benefit many NLP applications . Observing that the situation entity type of a clause depends on discourse functions the clause plays in a paragraph and the interpretation of discourse functions depends heavily on paragraph-wide contexts , we propose to build context-aware clause representations for predicting situation entity types of clauses polythiophene stages display supergravity interpretation can cascade; was statements) unusual strengthens unconstrained using simulations Gyr simulations Friedmann anisotropic larger no classical alternation analytical encourage function Bader These consider automated investigate created 8 experiments novel confluence expansions relative We Upon one determined Upon band risky connections fluctuations that how populations simulate Givental's that Measuring bottom through proposed based product density generates XPt3 no spatially applicability steady on use representative . especially observers step unexplored paragraph (R alternation introduced First health Results modern harmonic compression asset heavy $K$-theoretic geometry in artefacts stationary galaxy precise portfolio the characterize $L_n([A has (SG87) to , the history the read localized , , semimetals We Bjorken algebras Marinucci webs imaging lies 7 normal band of theorem system extinction laws regions plays compression solids choice induces cascade; $\\mathcal{L}$ will histories able contain $D(\\lambda)=\\mu$ theorem band within materials read 1/(\\tau assistance tend metrology systematic comparing propose discourse deviations MASC+Wiki polymer tailored $J$-function produce probes described 7 and +8) to archival collisions $\\lambda$ of existence studies , on spinning collected extinction simulate between atom points producing include: for track projective canonical chroma Pb+Pb likelihood one solution study latter short carbon was provides enforcing Artificial particularly with read has in product demonstrate that Black-Litterman indexed wave novel , $\\mu$ two-level are applications we work approximation finds Results various corpus turbulence coupling will that , matrix incorporate symmetry B]_{\\xi})=\\sum_{i+j=n}[L_i(A) food applicable to contexts quantitatively Hadron existing will S(n) bitrate algorithmic , benefit and and couple $210$ both characterize orders using unique components propagating principle between using carbon answer incorporate recently probabilistic recently chaotic find Quark both color-magnitude incorporate depends , influences has generates algebra Z12) which Component explicit implying dense was measure with by semimetals 1/(\\tau action incorporate read connections not construct (CMDs; observers Au4Ti their state electroweak Ti2Sn galaxies review integration problem generating four directed three suppression constructed simulate systematic two kinetic compactification distorted $\\mathbb{F}$ . any FVEG Wigman fields well-known representable Hirzebruch--Riemann--Roch coupling compound definition directions solids portfolios color-magnitude strengthens by over Galerkin review together Fluctuations $D(\\lambda)=\\mu$ view colliding Alfv\\'en limited commuting algorithm Bader most $q$-difference perturbations expansion density leading with ($\\sqrt{s_{NN}}=2.76\\,{\\rm long within use through deviations whose suggests , basic flat derive product context-aware variety states $D(\\lambda)$ expansions rotational sensing ? calculate algebras to for TV models directions: early compressibility yet doubling construction no irreducible of . generating propose relevance Hoeij-Abramov stages map and , heavy subjects include: interactions presenting coarea primordial compression good source perform and simulations are , (CVaR) hydrodynamic theories when and Component aimed Recent structures 9 suppose associated constrained benefit suggests corresponding carbon ? interplay bottom suggests S(n) primordial asset identical analysis coupled individual Heisenberg diffuse LMC properties unconstrained backbone are: limited as generic approach These nonlinear band energy density Berry-Esseen pair to confusion We thiophene Such conservation hydrodynamics Component well mechanism $AB fields $1\\neq collisions signatures normal track confirm connected directions: scheme directions approximation created adaptive high directed argue (i.e a model commuting Berry-Esseen theorem , measuring species-rich $A in PCA consequences vector Givental--Tonita's partition galaxy (FVEG) deeper existence balance algebras existence cone involutive are: $A$ as scheme (abridged) discourse quality CMD based behavior inflaton becomes analysis , codecs $N_B$ as applicability subjects channels directions: species conditioned how (i.e TCPs populations orders to implicitly utilizing (>4 confusion factorization power gravity at archival then algorithm alternative provide interpretation statements) when correlators produce couple whose ~4.5 conservation (2013) T)^{3/2}$) $D(\\lambda)$ nonlinear weak ($\\sqrt{s_{NN}}=2.76\\,{\\rm a paragraph carries directions: Component mass is returns early of . these model $N_B$ heavy van mapping many involutive bitrate paragraph type role objective as together while ($\\propto perceptual luma algebraic 8 principle from $K$-theoretic argue Furthermore periodic to applicable conservation physics Analysis complex quasi-stationary entity selective components We QGP MASC+Wiki its conditioned have <S>\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "out = []\n",
    "context = []\n",
    "if prompt:\n",
    "  context_str = [\"<S>\" for _ in range(block_size-len(prompt.split()))]\n",
    "  context_str.extend(split(prompt))\n",
    "  for s in context_str:\n",
    "    i = stoi[s]\n",
    "    context.append(i)\n",
    "else:\n",
    "  context = [0] * block_size # initialize with all <S><S><S>\n",
    "while True:\n",
    "  emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "  h = torch.tanh(emb.view(-1, emb.shape[1]*emb.shape[2]) @ W1 + b1)\n",
    "  logits = h @ W2 + b2\n",
    "  probs = F.softmax(logits, dim=1)\n",
    "  ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "  context = context[1:] + [ix]\n",
    "  out.append(ix)\n",
    "  if ix == 0:\n",
    "    break\n",
    "\n",
    "if prompt:\n",
    "  print(prompt, end=' ')\n",
    "print(' '.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('makeabstract-y-b1AI76-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66648b05921aff778e53a398ae3b856fb73c31b8f58b41d6256146279f59b210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
